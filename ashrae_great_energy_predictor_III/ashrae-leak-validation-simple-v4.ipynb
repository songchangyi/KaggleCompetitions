{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# --- plotly ---\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# --- models ---\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16 or not. feather format does not support float16.\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            # skip datetime type or categorical type\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 312 ms, sys: 932 ms, total: 1.24 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "root = Path('../input/ashrae-feather-format-for-fast-loading')\n",
    "\n",
    "#train_df = pd.read_feather(root/'train.feather')\n",
    "test_df = pd.read_feather(root/'test.feather')\n",
    "#weather_train_df = pd.read_feather(root/'weather_train.feather')\n",
    "#weather_test_df = pd.read_feather(root/'weather_test.feather')\n",
    "building_meta_df = pd.read_feather(root/'building_metadata.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i'm now using my leak data station kernel to shortcut.\n",
    "leak_df = pd.read_feather('../input/ashrae-leak-data-station/leak.feather')\n",
    "\n",
    "leak_df.fillna(0, inplace=True)\n",
    "leak_df = leak_df[(leak_df.timestamp.dt.year > 2016) & (leak_df.timestamp.dt.year < 2019)]\n",
    "leak_df.loc[leak_df.meter_reading < 0, 'meter_reading'] = 0 # remove large negative values\n",
    "leak_df = leak_df[leak_df.building_id!=245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/arraysetops.py:568: FutureWarning:\n",
      "\n",
      "elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_submission1 = pd.read_csv('../input/ashrae-kfold-lightgbm-without-leak-1-08/submission.csv', index_col=0)\n",
    "sample_submission2 = pd.read_csv('../input/ashrae-half-and-half/submission.csv', index_col=0)\n",
    "sample_submission3 = pd.read_csv('../input/ashrae-highway-kernel-route4/submission.csv', index_col=0)\n",
    "#sample_submission4 = pd.read_csv('../input/ashrae-exploiting-leak-site-5/submission.csv', index_col=0)\n",
    "sample_submission4 = pd.read_csv('../input/ashrae-energy-prediction-using-stratified-kfold/fe2_lgbm.csv', index_col=0)\n",
    "#sample_submission5 = pd.read_csv('../input/ashrae-simple-data-cleanup-lb-1-08-no-leaks/submission.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1869.00 MB\n",
      "Memory usage after optimization is: 1232.74 MB\n",
      "Decreased by 34.0%\n",
      "Memory usage of dataframe is 460.05 MB\n",
      "Memory usage after optimization is: 299.03 MB\n",
      "Decreased by 35.0%\n"
     ]
    }
   ],
   "source": [
    "test_df['pred1'] = sample_submission1.meter_reading\n",
    "test_df['pred2'] = sample_submission2.meter_reading\n",
    "test_df['pred3'] = sample_submission3.meter_reading\n",
    "test_df['pred4'] = sample_submission4.meter_reading\n",
    "\n",
    "test_df.loc[test_df.pred1<0, 'pred1'] = 0\n",
    "test_df.loc[test_df.pred2<0, 'pred2'] = 0\n",
    "test_df.loc[test_df.pred3<0, 'pred3'] = 0\n",
    "test_df.loc[test_df.pred4<0, 'pred4'] = 0\n",
    "\n",
    "del  sample_submission1,  sample_submission2,  sample_submission3, sample_submission4\n",
    "gc.collect()\n",
    "\n",
    "test_df = reduce_mem_usage(test_df)\n",
    "leak_df = reduce_mem_usage(leak_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df = leak_df.merge(test_df[['building_id', 'meter', 'timestamp', \n",
    "                                 'pred1', 'pred2', 'pred3', 'pred4',\n",
    "                                 'row_id']], \n",
    "                        left_on = ['building_id', 'meter', 'timestamp'], right_on = ['building_id', 'meter', 'timestamp'], how = \"left\")\n",
    "leak_df = leak_df.merge(building_meta_df[['building_id', 'site_id']], on='building_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df['pred1_l1p'] = np.log1p(leak_df.pred1)\n",
    "leak_df['pred2_l1p'] = np.log1p(leak_df.pred2)\n",
    "leak_df['pred3_l1p'] = np.log1p(leak_df.pred3)\n",
    "leak_df['pred4_l1p'] = np.log1p(leak_df.pred4)\n",
    "leak_df['meter_reading_l1p'] = np.log1p(leak_df.meter_reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1_l1p</th>\n",
       "      <th>pred2_l1p</th>\n",
       "      <th>pred3_l1p</th>\n",
       "      <th>pred4_l1p</th>\n",
       "      <th>meter_reading_l1p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred1_l1p</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.986133</td>\n",
       "      <td>0.988106</td>\n",
       "      <td>0.978432</td>\n",
       "      <td>0.862842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred2_l1p</th>\n",
       "      <td>0.986133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977993</td>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.856097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred3_l1p</th>\n",
       "      <td>0.988106</td>\n",
       "      <td>0.977993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966693</td>\n",
       "      <td>0.859570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred4_l1p</th>\n",
       "      <td>0.978432</td>\n",
       "      <td>0.968697</td>\n",
       "      <td>0.966693</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.867602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meter_reading_l1p</th>\n",
       "      <td>0.862842</td>\n",
       "      <td>0.856097</td>\n",
       "      <td>0.859570</td>\n",
       "      <td>0.867602</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pred1_l1p  pred2_l1p  pred3_l1p  pred4_l1p  \\\n",
       "pred1_l1p           1.000000   0.986133   0.988106   0.978432   \n",
       "pred2_l1p           0.986133   1.000000   0.977993   0.968697   \n",
       "pred3_l1p           0.988106   0.977993   1.000000   0.966693   \n",
       "pred4_l1p           0.978432   0.968697   0.966693   1.000000   \n",
       "meter_reading_l1p   0.862842   0.856097   0.859570   0.867602   \n",
       "\n",
       "                   meter_reading_l1p  \n",
       "pred1_l1p                   0.862842  \n",
       "pred2_l1p                   0.856097  \n",
       "pred3_l1p                   0.859570  \n",
       "pred4_l1p                   0.867602  \n",
       "meter_reading_l1p           1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leak_df[['pred1_l1p', 'pred2_l1p', 'pred3_l1p', 'pred4_l1p',\n",
    "         'meter_reading_l1p']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "#all_combinations = list(np.linspace(0.1,0.9,17))\n",
    "all_combinations = list(np.linspace(0,1,21))\n",
    "l = [all_combinations, all_combinations, all_combinations, all_combinations]\n",
    "# remember to do the reverse!\n",
    "all_l = list(itertools.product(*l)) + list(itertools.product(*reversed(l)))\n",
    "\n",
    "filtered_combis = [l for l in all_l if l[0] + l[1] + l[2] + l[3] > 0.93 and \n",
    "                   l[0] + l[1] + l[2] + l[3] < 1.03]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meter 0 : 0.68942237\n",
      "Weights (0.0, 0.05, 0.2, 0.7000000000000001)\n",
      "Meter 1 : 1.388696\n",
      "Weights (0.0, 0.0, 0.45, 0.5)\n",
      "Meter 2 : 0.9412642\n",
      "Weights (0.0, 0.15000000000000002, 0.30000000000000004, 0.55)\n",
      "Meter 3 : 1.0830786\n",
      "Weights (0.0, 0.1, 0.8, 0.05)\n",
      "CPU times: user 33min 8s, sys: 59.1 s, total: 34min 7s\n",
      "Wall time: 34min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_combi = []\n",
    "for m in [0,1,2,3]:\n",
    "    temp_df = leak_df[leak_df.meter==m]\n",
    "    best_combi = [] # of the form (i, score)\n",
    "    for i, combi in enumerate(filtered_combis):\n",
    "        #print(\"Now at: \" + str(i) + \" out of \" + str(len(filtered_combis))) # uncomment to view iterations\n",
    "        score1 = combi[0]\n",
    "        score2 = combi[1]\n",
    "        score3 = combi[2]\n",
    "        score4 = combi[3]\n",
    "        #score5 = combi[4]\n",
    "        v = score1 * temp_df['pred1'].values + \\\n",
    "            score2 * temp_df['pred2'].values + \\\n",
    "            score3 * temp_df['pred3'].values + \\\n",
    "            score4 * temp_df['pred4'].values\n",
    "        vl1p = np.log1p(v)\n",
    "        curr_score = np.sqrt(mean_squared_error(vl1p, temp_df.meter_reading_l1p))\n",
    "\n",
    "        if best_combi:\n",
    "            prev_score = best_combi[0][1]\n",
    "            if curr_score < prev_score:\n",
    "                best_combi[:] = []\n",
    "                best_combi += [(i, curr_score)]\n",
    "        else:\n",
    "            best_combi += [(i, curr_score)]\n",
    "\n",
    "    score = best_combi[0][1]\n",
    "    final_combi.append(filtered_combis[best_combi[0][0]])\n",
    "    print(\"Meter\", m, \":\", score)\n",
    "    print(\"Weights\", final_combi[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_feather(os.path.join(root, 'sample_submission.feather'))\n",
    "\n",
    "list_res = []\n",
    "test_df['meter_reading'] = 0\n",
    "for i in range(4):\n",
    "    w1, w2, w3, w4 = final_combi[i]\n",
    "    test_df.loc[test_df.meter==i, 'meter_reading'] = w1 * test_df.loc[test_df.meter==i, 'pred1'] + \\\n",
    "                                                     w2 * test_df.loc[test_df.meter==i, 'pred2'] + \\\n",
    "                                                     w3 * test_df.loc[test_df.meter==i, 'pred3'] + \\\n",
    "                                                     w4 * test_df.loc[test_df.meter==i, 'pred4']\n",
    "\n",
    "sample_submission['meter_reading'] = test_df['meter_reading']\n",
    "sample_submission.loc[sample_submission.meter_reading < 0, 'meter_reading'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_df = leak_df[['meter_reading', 'row_id']].set_index('row_id').dropna()\n",
    "sample_submission.loc[leak_df.index, 'meter_reading'] = leak_df['meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 31s, sys: 2.02 s, total: 4min 33s\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_submission.to_csv('submission_with_leak_by_site.csv', index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
